import torch
from torch import optim
from torch import nn
import argparse
from src.config import Config
from model.RESNET import resnet18,resnet34,resnet50,resnet101,resnet152
from model.vgg import VGG16
import os
import numpy as np
import random
from torchvision.datasets import ImageFolder
from torchvision import transforms as tfs
from torch.optim.lr_scheduler import _LRScheduler
from tensorboardX import SummaryWriter
from torch.autograd import Variable

def main(mode=None):
    
    config = load_config(mode)
    
    torch.manual_seed(config.SEED)
    torch.cuda.manual_seed(config.SEED)
    np.random.seed(config.SEED)
    random.seed(config.SEED)
    
    train_set = ImageFolder(config.TRAIN_PATH,transform=train_tf)
    length1 = len(train_set)
    train_data=torch.utils.data.DataLoader(train_set,batch_size=config.BATCH_SIZE,shuffle=True)
     iter_per_epoch = len(train.data)

    test_set = ImageFolder(config.TEST_PATH,transform=test_tf)
    test_data=torch.utils.data.DataLoader(test_set, batch_size=config.BATCH_SIZE, shuffle=False)
    
    # INIT GPU
    os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(e) for e in config.GPU)
    if torch.cuda.is_available():
        config.DEVICE = torch.device("cuda")
        print('\nGPU IS AVAILABLE')
        torch.backends.cudnn.benchmark = True
    else:
        config.DEVICE = torch.device("cpu")

     # choose network
    if config.MODEL == 1:
        net = VGG16().to(config.DEVICE)
        print('The Model is VGG\n')
    if config.MODEL == 2:
        net = resnet34().to(config.DEVICE)
        print('The Model is ResNet\n')        
     
    # choose train or test
    if config.MODE == 1:
        print("Start Training...\n")
        net.train()
    if config.MODE == 2:
        print("Start Testing...\n")
        net.test()

    optimizer = optim.SGD(net.parameters(),lr=config.LR，momentum=0.9,weight_decay=5e-4)
    loss_function = nn.CrossEntropyLoss()
    train_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=config.MILESTONES,gamma=0.1)
    warmup_scheduler = WarmUpLR(optimizer, iter_per_epoch * config.WARM)
#     optimizer = optim.Adam(net.parameters(),lr=float(config.LR),betas=(config.BETA1, config.BETA2))

# use tensorboard
    runs_path = os.path.join(config.PATH,'runs')
    if not os.path.exists(runs_path):
        os.mkdir(os.path.join(runs_path)
    writer = SummaryWriter(log_dir=os.path.join(runs_path,))
    input_tensor = torch.Tensor(12, 3, 32, 32).cuda()
    writer.add_graph(net, Variable(input_tensor, requires_grad=True))

#create checkpoint folder to save model
    if not os.path.exists(os.path.join(cinfig.PATH,'model')):
        os.mkdir(os.path.join(os.path.join(cinfig.PATH,'model'))
    checkpoint_path = os.path.join(config.PATH,'model','{epoch}-{type}.pth')
                 
    best_acc = 0.0
    for epoch in range(1, 80):
        if epoch > config.WARM:
            train_scheduler.step(epoch)
    
        train(epock)
        acc = eval_training(epock)
                 
      #start to save best performance model after learning rate decay to 0.01 
        if epoch > config.MILESTONES[1] and best_acc < acc:
            torch.save(net.state_dict(), checkpoint_path.format(net=args.net, epoch=epoch, type='best'))
            best_acc = acc
            continue

        if not epoch % config.SAVE_EPOCH:
            torch.save(net.state_dict(), checkpoint_path.format(epoch=epoch, type='regular'))
                 
    writer.close()

def train(epock):

    net.train()   
    train_loss = 0.0 # cost function error
    train_correct = 0.0
                 
    for i, data in enumerate(train_data):
                 
        if epoch <= args.warm:
            warmup_scheduler.step()
                 
        length = len(train_data)
        image, label = data
        image, label = image.to(config.DEVICE),label.to(config.DEVICE)

        output = net(image)
        test_correct += get_acc(output, label)
        loss = loss_function(output, label)
        train_loss +=loss.item()
                 
        # backward
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
                 
        n_iter = (epoch - 1) * len(train_data) + i + 1

        last_layer = list(net.children())[-1]
        for name, para in last_layer.named_parameters():
            if 'weight' in name:
                writer.add_scalar('LastLayerGradients/grad_norm2_weights', para.grad.norm(), n_iter)
            if 'bias' in name:
                writer.add_scalar('LastLayerGradients/grad_norm2_bias', para.grad.norm(), n_iter)

        print('Training Epoch: {epoch} [{trained_samples}/{total_samples}]\tLoss: {:0.4f}\tAcc: {:0.4f}LR: {:0.6f}'.format(
            train_loss,
            optimizer.param_groups[0]['lr'],
            
            epoch=epoch,
            trained_samples=i * config.BATCHSIZE + len(image),
            total_samples=len(train_data.dataset)
        ))

        #update training loss for each iteration
        writer.add_scalar('Train/loss', loss.item(), n_iter)

        for name, param in net.named_parameters():
            layer, attr = os.path.splitext(name)
            attr = attr[1:]
            writer.add_histogram("{}/{}".format(layer, attr), param, epoch)
       
                 
def eval_training(epoch):
    net.eval()

    test_loss = 0.0 # cost function error
    test_correct = 0.0

    for i, data in enumerate(test_data):
        images, labels = data
        images, labels = images.to(config.DEVICE),labels.to(config.DEVICE)

        outputs = net(images)
        loss = loss_function(outputs, labels)
        test_loss += loss.item()
        _, preds = outputs.max(1)
        test_correct += preds.eq(labels).sum()

    print('Test set: Average loss: {:.4f}, Accuracy: {:.4f}'.format(
        test_loss / len(cifar100_test_loader.dataset),
        correct.float() / len(cifar100_test_loader.dataset)
    ))
    print()

    #add informations to tensorboard
    writer.add_scalar('Test/Average loss', test_loss / len(test_data.dataset), epoch)
    writer.add_scalar('Test/Accuracy', test_correct.float() / len(test_data.dataset), epoch)

    return test_correct.float() / len(test_data.dataset)                 

        
def load_config(mode=None):
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--path', '--checkpoints', type=str, default='./checkpoints', help='model checkpoints path')

    args = parser.parse_args()
    config_path = os.path.join(args.path, 'config.yml')

    # load config file
    config = Config(config_path)

    # train mode
    if mode == 1:
        config.MODE = 1

    # test mode
    elif mode == 2:
        config.MODE = 2

    return config

def train_tf(x):
    config = load_config()
    x=x.resize((config.RESIZE,config.RESIZE))
    x=x.convert('RGB')
    im_aug = tfs.Compose([
        tfs.RandomHorizontalFlip(),  # default 0.5
        tfs.RandomCrop(config.CROP),
        tfs.ColorJitter(brightness=0.5, contrast=0.5, hue=0.5),
        tfs.ToTensor(),
        tfs.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    ])
    x = im_aug(x)
    return x

def test_tf(x):
    config = load_config()
    x=x.resize((config.RESIZE,config.RESIZE))
    x=x.convert('RGB')
    im_aug = tfs.Compose([
        tfs.CenterCrop(config.CROP),
        tfs.ToTensor(),
        tfs.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    ])
    x = im_aug(x)
    return x

def get_acc(output, label):
    total = output.shape[0]
    _, pred_label = output.max(1)           
    num_correct = (pred_label == label).sum().item()
    return num_correct / total


if __name__ == "__main__":
    main()
    
    
                     
                 #         train_loss += loss.item()
#         train_acc += get_acc(output, label)

#         print('[%d/%d, epoch:%d, iter:%d] Batch_Loss: %.03f | Batc_Acc: %.3f%% | Epoch_Loss: %.3f | Epock_Acc: %.3f%%'
#                       % ((i+1)*config.BATCH_SIZE, length1, epoch , (i + 1), loss.item(), 100 *get_acc(output, label), train_loss/(i+1), 100*train_acc/(i+1)))


#         if (i+1+epock*length)%50==0:
         

#                     val_loss = 0
#                     val_acc = 0
#                     net = net.eval()

#                 for _, data1 in enumrate(test_data):
#                     image, label = data
#                     image, label = image.to(config.DEVICE),label.to(config.DEVICE)

#                     with torch.no_grad():  
#                         output = net(image1)
#                         loss = criterion(output, label1)
#                         val_loss += loss.item()
#                         val_acc += get_acc(output, label1)
#                     epoch_str = (
#                         "Epoch %d. Train Loss: %f, Train Acc: %f, Valid Loss: %f, Valid Acc: %f, "
#                         % (epoch, train_loss / len(train_data),
#                         train_acc / len(train_data), valid_loss / len(valid_data),
#                         valid_acc / len(valid_data)))
#             else:
#                 epoch_str = ("Epoch %d. Train Loss: %f, Train Acc: %f, " %
#                              (epoch, train_loss / len(train_data),
#                               train_acc / len(train_data)))
#             prev_time = cur_time                        #到此处使得差为0
#             print(epoch_str + time_str)

